# Evaluating and Improving ChatGPT for Unit Test Generation

Yuan, Zhiqiang; Liu, Mingwei; Ding, Shiji; Wang, Kaixin; Chen, Yixuan; Peng, Xin; Lou, Yiling. "Evaluating and Improving ChatGPT for Unit Test Generation," in Proceedings of the ACM on Software Engineering, vol. 1, no. FSE, Article 76, Jul. 2024. doi: [10.1145/3660783](https://doi.org/10.1145/3660783)

## 1. Fichamento de Conteúdo

O artigo investiga a capacidade do _ChatGPT_ na geração de testes de unidade, abordando um problema comum no desenvolvimento de software, onde a criação manual de testes de alta qualidade é um processo demorado e propenso a erros. Embora ferramentas tradicionais de geração de testes sejam eficazes em termos de cobertura de código, elas falham em produzir testes legíveis e úteis para os desenvolvedores. O estudo realiza uma análise quantitativa e um estudo de usuário para avaliar os testes gerados pelo _ChatGPT_ em termos de corretude, suficiência, legibilidade e usabilidade. Os resultados mostram que, apesar de muitos testes gerados apresentarem erros de compilação ou falhas de execução, os testes bem-sucedidos se assemelham aos testes escritos manualmente. Inspirado nessas descobertas, o artigo propõe o _CHATTESTER_, uma abordagem que usa o próprio _ChatGPT_ em um processo iterativo para gerar e refinar testes. O _CHATTESTER_ obteve resultados significativamente melhores, aumentando a taxa de testes compiláveis em 34.3% e a taxa de testes com asserções corretas em 18.7% em comparação com o uso padrão do _ChatGPT_. A pesquisa conclui que a geração de testes de unidade com o _ChatGPT_ é promissora, desde que as questões de corretude sejam resolvidas.

## 2. Fichamento Bibliográfico

* Testes de Unidade (_Unit Testing_): Uma prática essencial no desenvolvimento de software para verificar se unidades de código (como métodos) funcionam corretamente. Essa validação é crucial para encontrar _bugs_ em estágios iniciais.
* Modelos de Linguagem Grandes (_Large Language Models_): Modelos de inteligência artificial de grande escala, pré-treinados em vastos corpos de texto e código, que têm se mostrado promissores na geração de testes mais "humanizados".
* _CHATTESTER_: Uma técnica proposta pelo artigo que utiliza o próprio _ChatGPT_ em um processo de duas partes (um gerador inicial e um refinador iterativo) para melhorar a corretude dos testes de unidade gerados.
* Gerador de Teste Inicial (_Initial Test Generator_): O primeiro componente do _CHATTESTER_, que solicita ao _ChatGPT_ que primeiro compreenda a intenção de um método antes de gerar o teste, a fim de criar asserções mais precisas.
* Refinador de Teste Iterativo (_Iterative Test Refiner_): O segundo componente do _CHATTESTER_, que corrige erros de compilação nos testes. Ele faz isso de forma iterativa, usando as mensagens de erro do compilador para guiar o _ChatGPT_ na correção do código.

## 3. Fichamento de Citações

* _"Manually writing high-quality unit tests is time-consuming and laborious."_
* _"The tests generated by ChatGPT still suffer from correctness issues, including diverse compilation errors and execution failures (mostly caused by incorrect assertions); but the passing tests generated by ChatGPT almost resemble manually-written tests..."_
* _"Our findings indicate that generating unit tests with ChatGPT could be very promising if the correctness of its generated tests could be further improved."_
* _"Inspired by our findings above, we further propose CHATTESTER, a novel ChatGPT-based unit test generation approach, which leverages ChatGPT itself to improve the quality of its generated tests."_
* _"On the bad side, we find that only a portion (24.8%) of tests generated by ChatGPT can pass the execution and the remaining tests suffer from diverse correctness issues."_
* _"On the good side, we find the passing tests generated by ChatGPT actually resemble manually-written ones by achieving comparable coverage, readability, and sometimes even developers' preference compared to manually-written ones."_